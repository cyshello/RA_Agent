#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
JSON íŒŒì¼ì„ MariaDB/MySQLì— ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ì„ë² ë”© í¬í•¨)

ì‚¬ìš©ë²•:
    python load_json_to_db.py [options]
    
ì˜ˆì‹œ:
    # ì „ì²´ ë¡œë“œ (ì„ë² ë”© í¬í•¨)
    python load_json_to_db.py
    
    # íŠ¹ì • íƒ€ì…ë§Œ ë¡œë“œ
    python load_json_to_db.py --type project
    python load_json_to_db.py --type management
    python load_json_to_db.py --type inclusive
    
    # DB ì´ˆê¸°í™” í›„ ë¡œë“œ
    python load_json_to_db.py --reset
"""

import argparse
import json
import os
import sys
from datetime import datetime
from typing import List, Dict, Any

import pymysql
import dotenv
from openai import OpenAI

# ê¸°ë³¸ ì„¤ì •
DEFAULT_DB_HOST = "localhost"
DEFAULT_DB_PORT = 3306
DEFAULT_DB_NAME = "b2g_data"
DEFAULT_DB_USER = "root"
DEFAULT_DB_PASSWORD = ""

# ì„ë² ë”© ì„¤ì •
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIM = 1536

# JSON íŒŒì¼ ê²½ë¡œ (ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬)
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_JSON = os.path.join(SCRIPT_DIR, "project.json")
MANAGEMENT_JSON = os.path.join(SCRIPT_DIR, "management.json")
INCLUSIVE_JSON = os.path.join(SCRIPT_DIR, "inclusive.json")

# OpenAI API í‚¤ ë¡œë“œ
env_path = os.path.join(os.path.dirname(SCRIPT_DIR), "src", ".env")
if os.path.exists(env_path):
    OPENAI_KEY = dotenv.get_key(env_path, "OPENAI_KEY")
else:
    OPENAI_KEY = os.environ.get("OPENAI_API_KEY")

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = None


def get_connection(host: str, port: int, database: str, user: str, password: str):
    """MySQL/MariaDB ì—°ê²° ìƒì„±"""
    return pymysql.connect(
        host=host,
        port=port,
        database=database,
        user=user,
        password=password,
        charset='utf8mb4',
        cursorclass=pymysql.cursors.DictCursor
    )


def create_tables(conn):
    """í…Œì´ë¸” ìƒì„± (ì‚­ì œ í›„ ì¬ìƒì„±) - ì„ë² ë”© ì»¬ëŸ¼ í¬í•¨"""
    with conn.cursor() as cursor:
        # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ í›„ ì¬ìƒì„±
        cursor.execute("DROP TABLE IF EXISTS national_projects")
        cursor.execute("DROP TABLE IF EXISTS management_evals")
        cursor.execute("DROP TABLE IF EXISTS inclusive_growth")
        
        # êµ­ì •ê³¼ì œ í…Œì´ë¸” (ì„ë² ë”© í¬í•¨)
        cursor.execute(f"""
            CREATE TABLE national_projects (
                id INT AUTO_INCREMENT PRIMARY KEY,
                ê³¼ì œëª… VARCHAR(500) NOT NULL,
                ê³¼ì œë²ˆí˜¸ VARCHAR(50),
                ê³¼ì œ_ëª©í‘œ LONGTEXT,
                ì£¼ìš”ë‚´ìš© LONGTEXT,
                ê¸°ëŒ€íš¨ê³¼ LONGTEXT,
                source_document VARCHAR(255),
                page_range VARCHAR(50),
                extraction_date VARCHAR(50),
                embedding_text LONGTEXT,
                embedding BLOB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        # FULLTEXT ì¸ë±ìŠ¤ ë³„ë„ ìƒì„±
        cursor.execute("""
            ALTER TABLE national_projects 
            ADD FULLTEXT INDEX ft_project (ê³¼ì œëª…, ê³¼ì œ_ëª©í‘œ, ì£¼ìš”ë‚´ìš©, ê¸°ëŒ€íš¨ê³¼) WITH PARSER ngram
        """)
        
        # ê²½ì˜í‰ê°€ í…Œì´ë¸” (ì„ë² ë”© í¬í•¨)
        cursor.execute(f"""
            CREATE TABLE management_evals (
                id INT AUTO_INCREMENT PRIMARY KEY,
                ì§€í‘œëª… VARCHAR(500) NOT NULL,
                í‰ê°€ê¸°ì¤€ LONGTEXT,
                í‰ê°€ë°©ë²• LONGTEXT,
                ì°¸ê³ ì‚¬í•­ LONGTEXT,
                ì¦ë¹™ìë£Œ LONGTEXT,
                source_document VARCHAR(255),
                page_range VARCHAR(50),
                extraction_date VARCHAR(50),
                embedding_text LONGTEXT,
                embedding BLOB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        cursor.execute("""
            ALTER TABLE management_evals 
            ADD FULLTEXT INDEX ft_management (ì§€í‘œëª…, í‰ê°€ê¸°ì¤€, í‰ê°€ë°©ë²•, ì°¸ê³ ì‚¬í•­) WITH PARSER ngram
        """)
        
        # ë™ë°˜ì„±ì¥ í…Œì´ë¸” (ì„ë² ë”© í¬í•¨)
        cursor.execute(f"""
            CREATE TABLE inclusive_growth (
                id INT AUTO_INCREMENT PRIMARY KEY,
                ì§€í‘œëª… VARCHAR(500) NOT NULL,
                í‰ê°€ê¸°ì¤€ LONGTEXT,
                í‰ê°€ë°©ë²• LONGTEXT,
                ì°¸ê³ ì‚¬í•­ LONGTEXT,
                ì¦ë¹™ìë£Œ LONGTEXT,
                source_document VARCHAR(255),
                page_range VARCHAR(50),
                extraction_date VARCHAR(50),
                embedding_text LONGTEXT,
                embedding BLOB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """)
        
        cursor.execute("""
            ALTER TABLE inclusive_growth 
            ADD FULLTEXT INDEX ft_inclusive (ì§€í‘œëª…, í‰ê°€ê¸°ì¤€, í‰ê°€ë°©ë²•, ì°¸ê³ ì‚¬í•­) WITH PARSER ngram
        """)
        
    conn.commit()
    print("âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ (ì„ë² ë”© ì»¬ëŸ¼ í¬í•¨)")


def reset_tables(conn):
    """í…Œì´ë¸” ë°ì´í„°ë§Œ ì´ˆê¸°í™” (í…Œì´ë¸” ìœ ì§€)"""
    with conn.cursor() as cursor:
        cursor.execute("TRUNCATE TABLE national_projects")
        cursor.execute("TRUNCATE TABLE management_evals")
        cursor.execute("TRUNCATE TABLE inclusive_growth")
    conn.commit()
    print("ğŸ—‘ï¸  ëª¨ë“  í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì™„ë£Œ")


def init_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global openai_client
    if openai_client is None:
        if not OPENAI_KEY:
            print("âš ï¸  OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì„ë² ë”© ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
            return None
        openai_client = OpenAI(api_key=OPENAI_KEY)
    return openai_client


def get_embedding(text: str) -> bytes:
    """í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•˜ì—¬ ë°”ì´ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    import struct
    
    client = init_openai_client()
    if client is None or not text.strip():
        return None
    
    try:
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text[:8000]  # í† í° ì œí•œ
        )
        embedding = response.data[0].embedding
        # float ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”ì´ë„ˆë¦¬ë¡œ ë³€í™˜
        return struct.pack(f'{len(embedding)}f', *embedding)
    except Exception as e:
        print(f"  âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def get_embeddings_batch(texts: List[str], batch_size: int = 100) -> List[bytes]:
    """ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±"""
    import struct
    
    client = init_openai_client()
    if client is None:
        return [None] * len(texts)
    
    results = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        # ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        batch = [t[:8000] if t.strip() else " " for t in batch]
        
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=batch
            )
            for item in response.data:
                embedding = item.embedding
                results.append(struct.pack(f'{len(embedding)}f', *embedding))
        except Exception as e:
            print(f"  âš ï¸ ë°°ì¹˜ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            results.extend([None] * len(batch))
    
    return results


def list_to_text(items: List) -> str:
    """ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not items:
        return ""
    if isinstance(items, list):
        return "\n".join(str(item) for item in items if item)
    return str(items)


def load_projects(conn, json_path: str) -> int:
    """êµ­ì •ê³¼ì œ ë°ì´í„° ë¡œë“œ (ì„ë² ë”© í¬í•¨)"""
    if not os.path.exists(json_path):
        print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {json_path}")
        return 0
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not data:
        print("âš ï¸  êµ­ì •ê³¼ì œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        return 0
    
    # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
    print("   ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘...")
    embedding_texts = []
    for item in data:
        ê³¼ì œëª… = item.get('ê³¼ì œëª…', '')
        ê³¼ì œëª©í‘œ = list_to_text(item.get('ê³¼ì œ ëª©í‘œ', []))
        ì£¼ìš”ë‚´ìš© = list_to_text(item.get('ì£¼ìš”ë‚´ìš©', []))
        ê¸°ëŒ€íš¨ê³¼ = list_to_text(item.get('ê¸°ëŒ€íš¨ê³¼', []))
        
        # ì„ë² ë”©ìš© í†µí•© í…ìŠ¤íŠ¸
        embed_text = f"ê³¼ì œëª…: {ê³¼ì œëª…}\nëª©í‘œ: {ê³¼ì œëª©í‘œ}\nì£¼ìš”ë‚´ìš©: {ì£¼ìš”ë‚´ìš©}\nê¸°ëŒ€íš¨ê³¼: {ê¸°ëŒ€íš¨ê³¼}"
        embedding_texts.append(embed_text)
    
    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    embeddings = get_embeddings_batch(embedding_texts)
    
    count = 0
    with conn.cursor() as cursor:
        for i, item in enumerate(data):
            try:
                ê³¼ì œëª… = item.get('ê³¼ì œëª…', '')
                ê³¼ì œëª©í‘œ = list_to_text(item.get('ê³¼ì œ ëª©í‘œ', []))
                ì£¼ìš”ë‚´ìš© = list_to_text(item.get('ì£¼ìš”ë‚´ìš©', []))
                ê¸°ëŒ€íš¨ê³¼ = list_to_text(item.get('ê¸°ëŒ€íš¨ê³¼', []))
                
                cursor.execute("""
                    INSERT INTO national_projects 
                    (ê³¼ì œëª…, ê³¼ì œë²ˆí˜¸, ê³¼ì œ_ëª©í‘œ, ì£¼ìš”ë‚´ìš©, ê¸°ëŒ€íš¨ê³¼, source_document, page_range, extraction_date, embedding_text, embedding)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    ê³¼ì œëª…,
                    item.get('ê³¼ì œë²ˆí˜¸', ''),
                    ê³¼ì œëª©í‘œ,
                    ì£¼ìš”ë‚´ìš©,
                    ê¸°ëŒ€íš¨ê³¼,
                    item.get('source_document', 'project.json'),
                    item.get('page_range', ''),
                    item.get('extraction_date', datetime.now().isoformat()),
                    embedding_texts[i],
                    embeddings[i]
                ))
                count += 1
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {item.get('ê³¼ì œëª…', 'Unknown')[:30]} - {e}")
    
    conn.commit()
    return count


def load_management(conn, json_path: str) -> int:
    """ê²½ì˜í‰ê°€ ë°ì´í„° ë¡œë“œ (ì„ë² ë”© í¬í•¨)"""
    if not os.path.exists(json_path):
        print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {json_path}")
        return 0
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not data:
        print("âš ï¸  ê²½ì˜í‰ê°€ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        return 0
    
    # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
    print("   ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘...")
    embedding_texts = []
    for item in data:
        ì§€í‘œëª… = item.get('ì§€í‘œëª…', '')
        í‰ê°€ê¸°ì¤€ = list_to_text(item.get('í‰ê°€ê¸°ì¤€', []))
        í‰ê°€ë°©ë²• = list_to_text(item.get('í‰ê°€ë°©ë²•', []))
        ì°¸ê³ ì‚¬í•­ = list_to_text(item.get('ì°¸ê³ ì‚¬í•­', []))
        
        embed_text = f"ì§€í‘œëª…: {ì§€í‘œëª…}\ní‰ê°€ê¸°ì¤€: {í‰ê°€ê¸°ì¤€}\ní‰ê°€ë°©ë²•: {í‰ê°€ë°©ë²•}\nì°¸ê³ ì‚¬í•­: {ì°¸ê³ ì‚¬í•­}"
        embedding_texts.append(embed_text)
    
    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    embeddings = get_embeddings_batch(embedding_texts)
    
    count = 0
    with conn.cursor() as cursor:
        for i, item in enumerate(data):
            try:
                ì§€í‘œëª… = item.get('ì§€í‘œëª…', '')
                í‰ê°€ê¸°ì¤€ = list_to_text(item.get('í‰ê°€ê¸°ì¤€', []))
                í‰ê°€ë°©ë²• = list_to_text(item.get('í‰ê°€ë°©ë²•', []))
                ì°¸ê³ ì‚¬í•­ = list_to_text(item.get('ì°¸ê³ ì‚¬í•­', []))
                ì¦ë¹™ìë£Œ = list_to_text(item.get('ì¦ë¹™ìë£Œ', []))
                
                cursor.execute("""
                    INSERT INTO management_evals 
                    (ì§€í‘œëª…, í‰ê°€ê¸°ì¤€, í‰ê°€ë°©ë²•, ì°¸ê³ ì‚¬í•­, ì¦ë¹™ìë£Œ, source_document, page_range, extraction_date, embedding_text, embedding)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    ì§€í‘œëª…,
                    í‰ê°€ê¸°ì¤€,
                    í‰ê°€ë°©ë²•,
                    ì°¸ê³ ì‚¬í•­,
                    ì¦ë¹™ìë£Œ,
                    item.get('source_document', 'management.json'),
                    item.get('page_range', ''),
                    item.get('extraction_date', datetime.now().isoformat()),
                    embedding_texts[i],
                    embeddings[i]
                ))
                count += 1
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {item.get('ì§€í‘œëª…', 'Unknown')[:30]} - {e}")
    
    conn.commit()
    return count


def load_inclusive(conn, json_path: str) -> int:
    """ë™ë°˜ì„±ì¥ ë°ì´í„° ë¡œë“œ (ì„ë² ë”© í¬í•¨)"""
    if not os.path.exists(json_path):
        print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {json_path}")
        return 0
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not data:
        print("âš ï¸  ë™ë°˜ì„±ì¥ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        return 0
    
    # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
    print("   ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘...")
    embedding_texts = []
    for item in data:
        ì§€í‘œëª… = item.get('ì§€í‘œëª…', '')
        í‰ê°€ê¸°ì¤€ = list_to_text(item.get('í‰ê°€ê¸°ì¤€', []))
        í‰ê°€ë°©ë²• = list_to_text(item.get('í‰ê°€ë°©ë²•', []))
        ì°¸ê³ ì‚¬í•­ = list_to_text(item.get('ì°¸ê³ ì‚¬í•­', []))
        
        embed_text = f"ì§€í‘œëª…: {ì§€í‘œëª…}\ní‰ê°€ê¸°ì¤€: {í‰ê°€ê¸°ì¤€}\ní‰ê°€ë°©ë²•: {í‰ê°€ë°©ë²•}\nì°¸ê³ ì‚¬í•­: {ì°¸ê³ ì‚¬í•­}"
        embedding_texts.append(embed_text)
    
    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    embeddings = get_embeddings_batch(embedding_texts)
    
    count = 0
    with conn.cursor() as cursor:
        for i, item in enumerate(data):
            try:
                ì§€í‘œëª… = item.get('ì§€í‘œëª…', '')
                í‰ê°€ê¸°ì¤€ = list_to_text(item.get('í‰ê°€ê¸°ì¤€', []))
                í‰ê°€ë°©ë²• = list_to_text(item.get('í‰ê°€ë°©ë²•', []))
                ì°¸ê³ ì‚¬í•­ = list_to_text(item.get('ì°¸ê³ ì‚¬í•­', []))
                ì¦ë¹™ìë£Œ = list_to_text(item.get('ì¦ë¹™ìë£Œ', []))
                
                cursor.execute("""
                    INSERT INTO inclusive_growth 
                    (ì§€í‘œëª…, í‰ê°€ê¸°ì¤€, í‰ê°€ë°©ë²•, ì°¸ê³ ì‚¬í•­, ì¦ë¹™ìë£Œ, source_document, page_range, extraction_date, embedding_text, embedding)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    ì§€í‘œëª…,
                    í‰ê°€ê¸°ì¤€,
                    í‰ê°€ë°©ë²•,
                    ì°¸ê³ ì‚¬í•­,
                    ì¦ë¹™ìë£Œ,
                    item.get('source_document', 'inclusive.json'),
                    item.get('page_range', ''),
                    item.get('extraction_date', datetime.now().isoformat()),
                    embedding_texts[i],
                    embeddings[i]
                ))
                count += 1
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {item.get('ì§€í‘œëª…', 'Unknown')[:30]} - {e}")
    
    conn.commit()
    return count


def show_stats(conn):
    """DB í†µê³„ ì¶œë ¥"""
    with conn.cursor() as cursor:
        cursor.execute("SELECT COUNT(*) as cnt FROM national_projects")
        projects = cursor.fetchone()['cnt']
        
        cursor.execute("SELECT COUNT(*) as cnt FROM management_evals")
        management = cursor.fetchone()['cnt']
        
        cursor.execute("SELECT COUNT(*) as cnt FROM inclusive_growth")
        inclusive = cursor.fetchone()['cnt']
        
        # ì„ë² ë”© ìˆëŠ” í•­ëª© ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) as cnt FROM national_projects WHERE embedding IS NOT NULL")
        projects_embed = cursor.fetchone()['cnt']
        
        cursor.execute("SELECT COUNT(*) as cnt FROM management_evals WHERE embedding IS NOT NULL")
        management_embed = cursor.fetchone()['cnt']
        
        cursor.execute("SELECT COUNT(*) as cnt FROM inclusive_growth WHERE embedding IS NOT NULL")
        inclusive_embed = cursor.fetchone()['cnt']
    
    print()
    print("=" * 50)
    print("ğŸ“Š DB í˜„í™©")
    print("=" * 50)
    print(f"  êµ­ì •ê³¼ì œ:    {projects:>5}ê°œ (ì„ë² ë”©: {projects_embed}ê°œ)")
    print(f"  ê²½ì˜í‰ê°€:    {management:>5}ê°œ (ì„ë² ë”©: {management_embed}ê°œ)")
    print(f"  ë™ë°˜ì„±ì¥:    {inclusive:>5}ê°œ (ì„ë² ë”©: {inclusive_embed}ê°œ)")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ì´ê³„:        {projects + management + inclusive:>5}ê°œ")
    print("=" * 50)


def main():
    parser = argparse.ArgumentParser(
        description='JSON íŒŒì¼ì„ MariaDB/MySQLì— ë¡œë“œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python load_json_to_db.py                    # ì „ì²´ ë¡œë“œ
  python load_json_to_db.py --type project     # êµ­ì •ê³¼ì œë§Œ ë¡œë“œ
  python load_json_to_db.py --type management  # ê²½ì˜í‰ê°€ë§Œ ë¡œë“œ
  python load_json_to_db.py --type inclusive   # ë™ë°˜ì„±ì¥ë§Œ ë¡œë“œ
  python load_json_to_db.py --reset            # DB ì´ˆê¸°í™” í›„ ë¡œë“œ
        """
    )
    
    parser.add_argument('--type', '-t', choices=['project', 'management', 'inclusive', 'all'],
                        default='all', help='ë¡œë“œí•  ë°ì´í„° íƒ€ì… (ê¸°ë³¸: all)')
    parser.add_argument('--reset', '-r', action='store_true', help='ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ë¡œë“œ')
    parser.add_argument('--db-host', default=DEFAULT_DB_HOST, help='DB í˜¸ìŠ¤íŠ¸')
    parser.add_argument('--db-port', type=int, default=DEFAULT_DB_PORT, help='DB í¬íŠ¸')
    parser.add_argument('--db-name', default=DEFAULT_DB_NAME, help='DB ì´ë¦„')
    parser.add_argument('--db-user', default=DEFAULT_DB_USER, help='DB ì‚¬ìš©ì')
    parser.add_argument('--db-password', default=DEFAULT_DB_PASSWORD, help='DB ë¹„ë°€ë²ˆí˜¸')
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸš€ JSON â†’ MariaDB ë¡œë“œ ì‹œì‘")
    print("=" * 50)
    print(f"  DB: {args.db_user}@{args.db_host}:{args.db_port}/{args.db_name}")
    print(f"  íƒ€ì…: {args.type}")
    print(f"  ì´ˆê¸°í™”: {'ì˜ˆ' if args.reset else 'ì•„ë‹ˆì˜¤'}")
    print("=" * 50)
    
    try:
        conn = get_connection(
            host=args.db_host,
            port=args.db_port,
            database=args.db_name,
            user=args.db_user,
            password=args.db_password
        )
        print("âœ… DB ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    try:
        # í…Œì´ë¸” ìƒì„±
        create_tables(conn)
        
        # ì´ˆê¸°í™”
        if args.reset:
            reset_tables(conn)
        
        # ë°ì´í„° ë¡œë“œ
        print()
        total = 0
        
        if args.type in ['project', 'all']:
            print(f"ğŸ“¥ êµ­ì •ê³¼ì œ ë¡œë“œ ì¤‘... ({PROJECT_JSON})")
            count = load_projects(conn, PROJECT_JSON)
            print(f"   â†’ {count}ê°œ ë¡œë“œ ì™„ë£Œ")
            total += count
        
        if args.type in ['management', 'all']:
            print(f"ğŸ“¥ ê²½ì˜í‰ê°€ ë¡œë“œ ì¤‘... ({MANAGEMENT_JSON})")
            count = load_management(conn, MANAGEMENT_JSON)
            print(f"   â†’ {count}ê°œ ë¡œë“œ ì™„ë£Œ")
            total += count
        
        if args.type in ['inclusive', 'all']:
            print(f"ğŸ“¥ ë™ë°˜ì„±ì¥ ë¡œë“œ ì¤‘... ({INCLUSIVE_JSON})")
            count = load_inclusive(conn, INCLUSIVE_JSON)
            print(f"   â†’ {count}ê°œ ë¡œë“œ ì™„ë£Œ")
            total += count
        
        print()
        print(f"âœ… ì´ {total}ê°œ í•­ëª© ë¡œë“œ ì™„ë£Œ")
        
        # í†µê³„ ì¶œë ¥
        show_stats(conn)
        
    finally:
        conn.close()


if __name__ == '__main__':
    main()
